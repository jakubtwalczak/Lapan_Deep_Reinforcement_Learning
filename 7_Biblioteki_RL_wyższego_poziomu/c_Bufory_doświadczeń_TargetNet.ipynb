{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOU5m8Zy16ALHO8Tb6Yb2BU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bufory doświadczeń"
      ],
      "metadata": {
        "id": "iIo1LN_kSmWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "import ptan\n",
        "import gym\n",
        "from typing import List, Optional, Tuple, Any\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F06k7gp5HHFl",
        "outputId": "84324776-9aa5-449c-e92c-a61aab495b0f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9ovpl-8qxAij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88e536a-57e0-4373-bb12-f7d198629b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class ToyEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(ToyEnv, self).__init__()\n",
        "        self.observation_space = gym.spaces.Discrete(n=5)\n",
        "        self.action_space = gym.spaces.Discrete(n=3)\n",
        "        self.step_index = 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.step_index = 0\n",
        "        return self.step_index, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        is_done = self.step_index == 10\n",
        "        if is_done:\n",
        "            return self.step_index % self.observation_space.n, \\\n",
        "                   0.0, is_done, False, {}\n",
        "        self.step_index += 1\n",
        "        return self.step_index % self.observation_space.n, \\\n",
        "               float(action), self.step_index == 10, False, {}\n",
        "\n",
        "\n",
        "class DullAgent(ptan.agent.BaseAgent):\n",
        "    def __init__(self, action: int):\n",
        "        self.action = action\n",
        "\n",
        "    def __call__(self, observations: List[Any],\n",
        "                 state: Optional[List] = None) \\\n",
        "            -> Tuple[List[int], Optional[List]]:\n",
        "        return [self.action for _ in observations], state"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# W głębokich sieciach Q korzystamy z fragmentów doświadczeń zebranych w buforach\n",
        "# Odczytywane są one w celu uzyskania paczki treningowej, losowo lub przy użyciu wag priorytetowych\n",
        "# Implementując je, powinniśmy zwrócić uwagę na:\n",
        "# 1. Efektywne pobieranie danych z dużego bufora\n",
        "# 2. Sposób usuwania starych danych\n",
        "# 3. Zarządzanie priorytetami w buforze priorytetowym\n",
        "# Kwestie te istotne są dla wydajności procesu treningowego\n",
        "\n",
        "# Biblioteka PTAN udostępnia kilka rodzajów buforów\n",
        "# Najprostszy jest ExperienceReplayBuffer o predefiniowanym rozmiarze i jednolitym próbkowaniu\n",
        "# Mamy też PrioritizedReplayBuffer i PrioReplayBufferNaive\n",
        "\n",
        "env = ToyEnv()\n",
        "agent = DullAgent(action=1)\n",
        "exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, gamma=1.0, steps_count=1)\n",
        "buffer = ptan.experience.ExperienceReplayBuffer(exp_source, buffer_size=100)"
      ],
      "metadata": {
        "id": "Bfo7wzmoI4Wd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pętla treningowa\n",
        "\n",
        "for step in range(6):\n",
        "    buffer.populate(1) # metoda pozwalająca na pobranie N próbek ze źródła doświadczenia i umieszczenie ich w buforze\n",
        "    if len(buffer) < 5:\n",
        "        continue\n",
        "    batch = buffer.sample(4) # metoda pozwalająca na pozyskanie paczki z N obiektami doświadczenia\n",
        "    print(\"Train time, %d batch samples:\" % len(batch))\n",
        "    for s in batch:\n",
        "        print(s)\n",
        "\n",
        "# po powyższych operacjach - we właściwej pętli:\n",
        "# 1. obliczenie straty\n",
        "# 2. użycie propagacji wstecznej\n",
        "# 3. powtórzenie kroków (łącznie z metodami populate() i sample()), aż do uzyskania stabilnych wyników"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj7v4CQSMdSZ",
        "outputId": "5f145857-a6ec-463f-d39d-b5a9bb4f59c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train time, 4 batch samples:\n",
            "ExperienceFirstLast(state=1, action=1, reward=1.0, last_state=2)\n",
            "ExperienceFirstLast(state=1, action=1, reward=1.0, last_state=2)\n",
            "ExperienceFirstLast(state=0, action=1, reward=1.0, last_state=1)\n",
            "ExperienceFirstLast(state=3, action=1, reward=1.0, last_state=4)\n",
            "Train time, 4 batch samples:\n",
            "ExperienceFirstLast(state=4, action=1, reward=1.0, last_state=0)\n",
            "ExperienceFirstLast(state=0, action=1, reward=1.0, last_state=1)\n",
            "ExperienceFirstLast(state=0, action=1, reward=1.0, last_state=1)\n",
            "ExperienceFirstLast(state=0, action=1, reward=1.0, last_state=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Klasa TargetNet"
      ],
      "metadata": {
        "id": "T-yWsGOFSlXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Klasa ta pozwala na synchronizację dwóch sieci neuronowych o tej samej architekturze\n",
        "# Dzięki temu stabilność procesu trenowania poprawia się\n",
        "# Dwa tryby synchronizacji:\n",
        "# 1. sync() - wagi sieci źródłowej są kopiowane do sieci docelowej\n",
        "# 2. alpha_sync() - wagi sieci źródłowej są łączone z wagami sieci docelowej przy użyciu współczynnika alfa (zakres 0 - 1)\n",
        "\n",
        "class DQNNet(nn.Module): # sieć źródłowa\n",
        "    def __init__(self, obs_size: int, n_actions: int):\n",
        "        super(DQNNet, self).__init__()\n",
        "        self.ff = nn.Linear(5, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.ff(x)\n",
        "\n",
        "net = DQNNet(5, 3)\n",
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyKH50lPSrz5",
        "outputId": "b7ef06e6-deba-4291-df2a-09fb8d4ded73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DQNNet(\n",
              "  (ff): Linear(in_features=5, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tgt_net = ptan.agent.TargetNet(net) # sieć docelowa\n",
        "print(net.ff.weight)\n",
        "print(tgt_net.target_model.ff.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JCh6qXDUlWw",
        "outputId": "f55d959f-6ae2-414c-c5e1-b019f40cbf9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0190, -0.4170, -0.2922, -0.1017, -0.1230],\n",
            "        [-0.4086, -0.2317,  0.2755, -0.1093, -0.0145],\n",
            "        [ 0.2008, -0.4454, -0.2162,  0.0386, -0.1118]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0190, -0.4170, -0.2922, -0.1017, -0.1230],\n",
            "        [-0.4086, -0.2317,  0.2755, -0.1093, -0.0145],\n",
            "        [ 0.2008, -0.4454, -0.2162,  0.0386, -0.1118]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wagi sieci źródłowej i docelowej są takie same\n",
        "# Sieci, mimo takiej samej architektury, są od siebie niezależne\n",
        "\n",
        "net.ff.weight.data += 1.0\n",
        "print(net.ff.weight)\n",
        "print(tgt_net.target_model.ff.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwA2Yv_RV-SR",
        "outputId": "e7891863-1109-4dc4-95f6-f0140839f052"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.9810, 0.5830, 0.7078, 0.8983, 0.8770],\n",
            "        [0.5914, 0.7683, 1.2755, 0.8907, 0.9855],\n",
            "        [1.2008, 0.5546, 0.7838, 1.0386, 0.8882]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0190, -0.4170, -0.2922, -0.1017, -0.1230],\n",
            "        [-0.4086, -0.2317,  0.2755, -0.1093, -0.0145],\n",
            "        [ 0.2008, -0.4454, -0.2162,  0.0386, -0.1118]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aby zsynchronizować sieci, możemy użyć metody sync()\n",
        "\n",
        "tgt_net.sync()\n",
        "print(tgt_net.target_model.ff.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwEo9da_WaY1",
        "outputId": "f382c9e5-48dd-4bb7-975b-e55de438e28d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.9810, 0.5830, 0.7078, 0.8983, 0.8770],\n",
            "        [0.5914, 0.7683, 1.2755, 0.8907, 0.9855],\n",
            "        [1.2008, 0.5546, 0.7838, 1.0386, 0.8882]], requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}